\newpage
\lecture{5}{Способ приближения для особых матриц.}

В прошлой лекции был рассмотрен алгоритм вычисления сингулярного разложения, придуманный Голубом и Каханом.
Там же были описаны недостатки данного алгоритма, один из которых~--- отсутствие использования каких-либо свойств матрицы.

В данной лекции будут рассматриваться способ вычисления приближения в предположении, что матрица имеет некие свойства.

\subsection{Приближение матрицей малого ранга.}

Пусть матрицу $A$ размера $n\times n$ можно приблизить матрицей малого ранга $B$ ($\rk(B) = r \ll n$). Задача в поиске матрицы $B$.
Более того можно усложнить задачу. Пусть матрица изначальна дана не как $n^2$ своих элементов, а как некая дискретная функция от
двух аргументов: $a(i,\, j) = a_{ij}$. В реальности часто так и бывает~--- матрицы слишком большие, чтобы была физическая возможность
сохранить/передать все элементы матрицы, в то время как такая функция может быть довольно компактной (в терминах потребляемой при
вычислении памяти).

Итак, есть \textit{априорная} информация, то есть $A$ приближается матрицей $B$, которую в свою очередь можно записать
как
\[
    B = UV^T=\vect{u}_1\vect{v}_1^T+\ldots+\vect{u}_r\vect{v}_r^T, \quad U = [\vect{u}_1,\,\ldots,\, \vect{u}_r],\,
    V = [\vect{v}_1,\,\ldots,\, \vect{v}_r].
\]
Именно в таком виде и будем искать матрицу $B$, то есть в виде сомножителей.

\subsubsection{А реально ли..?}

\begin{wrapfigure}{r}{0.35\textwidth}
    \centering
    \input{images/lect05_matrix.tikz}
    \caption{Матрица $A$ ($\rk(A)=r$).}
    \label{fig:lect05_matrix}
\end{wrapfigure}

Сразу возникает закономерный вопрос: \textit{возможно ли без вычисления \textbf{всех} элементов матрицы найти её приближение?}

Рассмотрим частный граничный случай. Пусть $\rk(A)=r$. Тогда существуют $r$ столбцов и $r$ строк такие, что
\[
    A = C \widehat{A}^{-1}R,
\]
где $C,\, R,\, \widehat{A}$ смотри на рисунке \ref{fig:lect05_matrix} (на рисунке строки и столбцы не обязательно расположены
последовательно). Будем также называть существование таких строк и столбцов, как \mdef{существует крест}.

\begin{remark}
    $\widehat{A}$~--- невырожденная.
\end{remark}

Итак, если найти крест мы найдем и решение поставленной задачи.

А что если $\rk(A)\neq r$? Этот вопрос сложный по нескольким причинам. Во-первых, даже если такая матрица $\widehat{A}$ есть, и она невырожденная,
в ней могут быть слишком большие элементы, а вспоминая прошлые лекции, это сильно сказывается на точности вычислений. Соответственно,
вопрос еще сильнее усложняется: \textit{можно ли получить приближение приемлимой точности?} Ответом на вопрос служит довольно молодая теорема, которая представлена ниже,
но сначала введем важное понятие:

\begin{definition}
    \mdef{Объемом} квадратной матрицы назовем модуль её определителя.
\end{definition}

\begin{remark}
    Определение довольно естественное если вспомнить, что
    объем параллелепипеда, натянутого на столбцы (строки) матрицы и есть модуль ее определителя.
\end{remark}

\begin{theorem}[Гореинов--Тыртышников, 2000 г.]
    Пусть матрица $A$ имеет блочный вид:
    \[
        A = \left[
            \begin{array}{c|c}
                A_{11} & A_{12} \\
                \hline
                A_{21} & A_{22}
            \end{array}
            \right],\quad \begin{array}{l}
            A_{11}\text{~--- матрица } r\times r, \\
            A_{11}\text{~--- блок максимального объема среди всех } r\times r\text{"=блоков } A.
        \end{array}
    \]
    Пусть также
    \[
        \sigma_1\geqslant \sigma_2\geqslant\ldots\geqslant\sigma_r\geqslant\sigma_{r+1}\geqslant\ldots\text{~--- сингулярные числа матрицы $A$.}
    \]

    Тогда
    \[
        \left\| A - \left[
            \begin{array}{c}
                A_{11} \\
                A_{21}
            \end{array}
            \right]\cdot A_{11}^{-1}\cdot \left[
            \begin{array}{cc}
                A_{11} & A_{12}
            \end{array}
            \right]\right\|_{C}\leqslant (r+1)\sigma_{r+1},
    \]
    где $\|A\|_C:=\max\limits_{i,\,j} |a_{ij}|$.

    \begin{proof}
        Распишем матрицу под знаком нормы:
        \begin{align*}
            \left[
                \begin{array}{cc}
                    A_{11} & A_{12} \\
                    A_{21} & A_{22}
                \end{array}
                \right]-\left[
                \begin{array}{c}
                    A_{11} \\
                    A_{21}
                \end{array}
                \right]\cdot A_{11}^{-1}\cdot \left[
                \begin{array}{cc}
                    A_{11} & A_{12}
                \end{array}
            \right] & =\left[
                \begin{array}{cc}
                    A_{11} & A_{12} \\
                    A_{21} & A_{22}
                \end{array}
                \right]-\left[
                \begin{array}{cc}
                    A_{11} & A_{12}                  \\
                    A_{21} & A_{21}A_{11}^{-1}A_{12}
                \end{array}
                \right]=      \\
                    & =\left[
                \begin{array}{cc}
                    0 & 0 \\
                    0 & H
                \end{array}
                \right], \quad \text{где }H = A_{22}-A_{21}A_{11}^{-1}A_{12}.
        \end{align*}

        \begin{remark}
            Матрица $H$ также называется \mdef{дополнением по Шуру} блока $A_{11}$ в матрице $A$.
        \end{remark}

        Нужно оценить максимальных элемент в матрице $H$. Рассмотрим элемент $\alpha$ в позиции $(i,\,j)$.
        Формулу выше можно написать для этого элемента таким образом: пусть $\vect{v}$~--- $i$"=ая строка,
        $\vect{u}$~--- $j$"=ый столбец, тогда:

        \[
            \underbrace{\left[
                    \begin{array}{cc}
                        A_{11}     & \vect{u} \\
                        \vect{v}^T & \alpha
                    \end{array}
                    \right]}_{\widetilde{A}} - \left[
                \begin{array}{c}
                    A_{11} \\
                    \vect{v}^T
                \end{array}
                \right]\cdot A_{11}^{-1}\cdot\left[
                \begin{array}{cc}
                    A_{11} & \vect{u}
                \end{array}
                \right] = \left[
                \begin{array}{cc}
                    0 & 0 \\
                    0 & h
                \end{array}
                \right], \quad h = \alpha - \vect{v}^TA_{11}^{-1}\vect{u}.
        \]

        Для оценки элемента $h$ нужно воспользоваться тем, что матрица $A_{11}$ имеет \textbf{наибольший} объем среди любых
        $r\times r$ подматриц. Проведем один шаг блочного исключения~--- обнулим $\vect{v}^T$:
        \[
            \underbrace{\left[
                    \begin{array}{cc}
                        I                      & 0 \\
                        -\vect{v}^TA_{11}^{-1} & 1
                    \end{array}
                    \right]}_{M}\cdot
            \left[
                \begin{array}{cc}
                    A_{11}     & \vect{u} \\
                    \vect{v}^T & \alpha
                \end{array}
                \right] = \left[
                \begin{array}{cc}
                    A_{11} & \vect{u} \\
                    0      & h
                \end{array}
                \right]
            \label{eq:delet}
        \]
        Теперь перейдем к обратным матрицам:
        \[
            \left[
                \begin{array}{cc}
                    A_{11}     & \vect{u} \\
                    \vect{v}^T & \alpha
                \end{array}
                \right]^{-1}\cdot\underbrace{\left[
                    \begin{array}{cc}
                        I                & 0 \\
                        \vect{v}^TA_{11} & 1
                    \end{array}
                    \right]}_{M^{-1}}=\left[
                \begin{array}{cc}
                    A_{11}^{-1} & -A_{11}^{-1}\vect{u}h^{-1} \\
                    0           & h^{-1}
                \end{array}
                \right]
        \]
        Далее умножим обе части справа на $M$:
        \[
            \left[
                \begin{array}{cc}
                    A_{11}     & \vect{u} \\
                    \vect{v}^T & \alpha
                \end{array}
                \right]^{-1}=\left[
                \begin{array}{cc}
                    A_{11}^{-1} & -A_{11}^{-1}\vect{u}h^{-1} \\
                    0           & h^{-1}
                \end{array}
                \right]\cdot \left[
                \begin{array}{cc}
                    I                      & 0 \\
                    -\vect{v}^TA_{11}^{-1} & 1
                \end{array}
                \right]=\left[
                \begin{array}{cc}
                    * & *      \\
                    * & h^{-1}
                \end{array}
                \right]
        \]

        Заметим, что $h^{-1}$~--- это элемент матрицы $\widetilde{A}^{-1}$ (определение $\widetilde{A}$ смотри выше) в правом нижнем углу.
        Рассмотрим определитель матрицы $\widetilde{A}$:
        \[
            |\widetilde{A}|=|A_{11}|\cdot |h|.
        \]
        Итак, если матрица $A_{11}$ имеет максимальный объем в $\widetilde{A}$, тогда $h^{-1}$~--- максимальный
        по модулю элемент матрицы $\widetilde{A}^{-1}$.

        Теперь рассмотрим сингулярную норму матрицы $\widetilde{A}^{-1}$:
        \[
            \|\widetilde{A}^{-1}\|_2=\sigma_{\max}(\widetilde{A}^{-1})\leqslant \|\widetilde{A}^{-1}\|_{F} =
            \sqrt{\sum_{i,\, j} |(\widetilde{A}^{-1})_{ij}|^2}\leqslant (r+1)|h^{-1}|
        \]

        Откуда получаем, что
        \[
            |h|\leqslant\dfrac{r+1}{\sigma_{\max}\left(\widetilde{A}^{-1}\right)}.
        \]

        Далее воспользуемся следующим утверждением (доказательство смотри в \nameref{sect:con})
        \begin{claim}
            Если $\widetilde{\sigma}_1\geqslant\ldots\geqslant\widetilde{\sigma}_r\geqslant\widetilde{\sigma}_{r+1}$~--- сингулярные числа
            матрицы $\widetilde{A}$, то сингулярные числа матрицы $\widetilde{A}^{-1}$~--- это
            $\widetilde{\sigma}^{-1}_1\leqslant\ldots\leqslant\widetilde{\sigma}^{-1}_{r+1}$.
        \end{claim}

        Итак,
        \[
            |h|\leqslant\dfrac{r+1}{\sigma_{\max}\left(\widetilde{A}^{-1}\right)}\leqslant(r +1)\cdot\sigma_{\min}(\widetilde{A}) =
            (r+1)\widetilde{\sigma}_{r+1}.
        \]

        Осталось понять почему $\widetilde{\sigma}_{r+1}\leqslant\sigma_{r+1}$. Здесь на помощь приходит важное утверждение:

        \begin{claim}[о соотношении разделения сингулярных чисел]
            Для матрицы $A$ и её подматрицы $\widetilde{A}$ порядка $k$ верно, что $\sigma_k(\widetilde{A})\leqslant\sigma_k(A)$.
        \end{claim}

    \end{proof}
\end{theorem}

\subsection{Немного об эрмитовых матрицах.}

Рассмотрим эрмитовую матрицу $A\in\Cx^{n\times n}$, то есть $A=A^*$. Занумеруем её собственные значения в порядке невозрастания:
$\lambda_{1}(A)\geqslant\ldots\geqslant\lambda_n(A)$. Справедлива следующая теорема (вариационная характеризация собственных значений):

\begin{theorem}[Куранта--Фишера]
    \[
        \lambda_k(A) = \max_{L_k}\min_{\substack{\vect{x}\in L_k\\ \vect{x}\neq 0}}
        \underbrace{\dfrac{(A\vect{x},\, \vect{x})}{(\vect{x},\,\vect{x})}}_{\substack{\text{отношение}\\\text{Рэлея}}},
    \]
    где $L_k$~--- пространство размерности $k$.
\end{theorem}

Еще существует так называемый закон инерции для эрмитовых матриц:

\begin{theorem}[закон инерции]
    Пусть $\nu_{+},\,\nu_{-},\,\nu_{0}$~--- число положительных, отрицательных и нулевых собственных значений соответственно.
    Тогда эта тройка сохраняется для конгруэнтных матриц:
    \[
        (\nu_{+},\, \nu_{-},\, \nu_{0})(A) = (\nu_{+},\, \nu_{-},\, \nu_{0})(P^*AP), \quad\forall\text{ невыржденной } P.
    \]
\end{theorem}

Можно доказать, что последние две теоремы эквивалентны (одна выводится из другой и наоборот). Более того существует еще
один факт, который эквивалентен этим двум.
\newpage

\begin{theorem}[соотношение разделения]
    Пусть матрица $A$~--- эрмитова. Пусть $B$~--- её подматрица порядка на 1 меньше. Тогда
    \[
        \lambda_1(A)\geqslant\lambda_1(B)\geqslant\lambda_2(A)\geqslant\lambda_2(B)\geqslant\ldots
    \]
\end{theorem}

\subsection{Связи сингулярных чисел.}
\label{sect:con}

Поставим такую задачу. Как связаны сингулярные числа матриц $A$ и $B=[A,\vect{u}]$?

Во-первых, $\sigma_i^2(A)$~--- собственные числа матрицы $A^*A$~--- эрмитова. Аналогично, если рассмотреть расширенную матрицу:
\[
    \left[
        \begin{array}{cc}
            A & \vect{u}
        \end{array}
        \right]^*\cdot\left[
        \begin{array}{cc}
            A & \vect{u}
        \end{array}
        \right]=\left[
        \begin{array}{c}
            A^* \\
            u^*
        \end{array}
        \right]\cdot\left[
        \begin{array}{cc}
            a & \vect{u}
        \end{array}
        \right] = \left[
        \begin{array}{c|c}
            A^*A        & A^*\vect{u}        \\
            \hline
            \vect{u}^*A & \vect{u}^*\vect{u}
        \end{array}
        \right].
\]
Откуда из соотношения разделения получаем, что $\sigma_k^2(B)\geqslant\sigma_k^2(A)$.

\subsection{Ещё один алгоритм...}

Еще не было оговорено, а как найти подматрицу наибольшего объема? Здесь поможет следующий алгоритм.

\begin{figure}[!ht]
    \centering
    \begin{minipage}{.5\textwidth}
        \centering
        \input{images/lect05_step1.tikz}
        \caption{Итог шага \protect\circled{1}.}
        \label{fig:lect05_algo}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \input{images/lect05_step2.tikz}
        \caption{Итерация в шаге \protect\circled{2}.}
        \label{fig:lect05_step2}
    \end{minipage}
\end{figure}

Пусть матрица имеет <<стоячий>> вид (смотри рисунок \ref{fig:lect05_algo}).

\begin{enumerate}[label=\protect\circled{\arabic*}]
    \item Найдем в матрице невырожденную подматрицу $k\times k$ и переместим ее наверх. Далее умножим матрицу справа
          на обратную к найденной невырожденной, в итоге получится матрица, вид которой изображен на рисунке \ref{fig:lect05_algo}. Отметим также
          что умножение на невыржденную матрицу не изменяет отношения объема.
    \item Теперь в нижней части матрицы найдем наибольшее число $a_{ij}$. Допустим, оно оказалось по модулю больше 1\footnote{на самом деле 
    можно сравнивать не с 1, а с $1+\delta$, то есть искать не максимальный объем, но близкий к нему.} 
    (иначе алгоритм завершен). 
    Тогда поменяем местами строки $i$ и $j$. Тогда модуль определителя верхней подматрицы станет равным $|a_{ij}|$, то есть нашли подматрицу большего объема. 
    Остается вернутся к пункту \protect\circled{1} и выполнить шаги еще раз.
\end{enumerate}