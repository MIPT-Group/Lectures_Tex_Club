\newpage
\lecture{2}{Параллельные алгоритмы, машинные числа, QR-разложение.}

\subsection{Параллельные вычисления.}

В прошлой лекции изучались такие понятия как алгоритм и его сложность. Как известно в настоящее время существуют устройства, которые
могут выполнять несколько операций за раз и, следовательно, хотелось бы анализировать сложность алгоритмов, выполняющихся данными
устройствами.

\begin{definition}
    \mdef{Параллельная сложность}~--- число параллельных шагов алгоритма, то есть шагов, за которые выполняются разом группа
    операций (параллельно).
\end{definition}

\begin{exercise}
    Зададимся вопросом, какова параллельная сложность алгоритма поиска LU-разложения. Первое наблюдение: когда обнуляется некоторый столбец, понятно, что
    обнулять каждую строчку можно независимо. Более того, при умножении строки на число и вычитании двух строк каждый элемент также можно считать независимо.
    А значит для обнуления одного столбца требуется один шаг, а значит общая параллельная сложность порядка $n$ (как и в прошлый раз $n$~--- порядок матрицы).
\end{exercise}

\begin{exercise}
    Применив аналогичные рассуждения, можно найти еще параллельную сложность поиска решения системы
    уравнений $Ux=b$, где $U$~--- верхняя треугольная матрица. Понятно, что в данном случае параллельная сложность составит тоже $\Theta(n)$.
\end{exercise}

\begin{remark}
    Стоит помнить, что несмотря на то, что много операций можно выполнить за раз, для каждой группы операций нужны какие-то
    данные, которые возможно не успели еще посчитаться, а значит какие-то шаги могут простаивать и ждать пока данные будут подготовлены,
    то есть возникает так называемая гонка за данными.
\end{remark}

\subsection{Представление чисел в компьютере.}

Машинные числа имеют вид:
\[
    10 ^ {p}  \cdot \overbrace{0.\underbrace{****\ldots **}_{t \text{ разрядов.}}}^{\text{мантисса}}, \quad p\text{~--- порядок.}
\]

Обычно количество разрядов $t$ фиксированно и порядок $p$ ограничен каким-то числом: $|p|\leqslant p_{\max}$, то есть не все вещественные числа
представляются таким образом, в том числе следует помнить, что при вычислениях получается именно машинное число, то есть не всегда
результат выражения совпадает с истинным (с точки зрения математики) ответом.

В силу этого появляется некая погрешность, о которой следует помнить.
\begin{exercise}
    Возьмем $t=3$. Что будет результатом вычисления $10^4+1$? Для начала каждое число нужно представить в экспоненциальной
    форме\footnote{форма в которой и представлены машинные числа.}. Итак, $10^4=10^5\cdot 0.100$, $1 = 10^1\cdot 0.100$.
    Чтобы найти сумму, нужно сравнять порядки чисел, в данном случае привести единицу к порядку 5, то есть представить в виде
    $10^5\cdot 0.00001$, но так как у нас число разрядов равно 3, то единица в 5"=ом знаке просто не вместится и число станет нулем.
    Тогда итоговое значение будет $10^4+1=10^4$, что конечно же противоречит истинному.

    \textbf{Вывод}: часто, если складываются очень большое и очень маленькое числа, вполне вероятно, что произойдет такая ситуация.
\end{exercise}

Попробуем теперь найти LU-разложение матрицы с учетом данного аспекта.

\begin{exercise}
    Пусть
    \[
        A = \left(
        \begin{array}{cc}
                10^{-t} & 1 \\
                1       & 1
            \end{array}
        \right),\quad t\text{~--- число разрядов.}
    \]

    Итак, обнуляем первый столбец (большое по модулю число $10^t$ <<съедает>> маленькую единицу в матрицах $L$ и $U$):
    \[
        U = \left(
        \begin{array}{cc}
                10^{-t} & 1      \\
                0       & 1-10^t
            \end{array}
        \right)=\left(
        \begin{array}{cc}
                10^{-t} & 1     \\
                0       & -10^t
            \end{array}
        \right), \quad L =\left(
        \begin{array}{cc}
                1    & 0 \\
                10^t & 1
            \end{array}
        \right).
    \]

    Давайте найдем $LU$:
    \[
        LU=\left(
        \begin{array}{cc}
                10^{-t} & 1 \\
                1       & 0
            \end{array}
        \right) = A - \underbrace{\left(
            \begin{array}{cc}
                0 & 0 \\
                0 & 1
            \end{array}
            \right)}_{\text{погрешность}}.
    \]
\end{exercise}

\subsection{Проблемы роста.}

Можно заметить, что проблема возникает из-за ведущего числа, которое сильно отличается от остальных. Формализуем машинные вычисления.
\begin{definition}
    Будем писать \mdef{$\fl(expr)$}~--- \textit{машинный} результат вычисления выражения $expr$.
    Например, на машине с $t=3: \fl(10^4+1)=10^4$.
\end{definition}

Итак, введем аксиому машинной арифметики:
\begin{axiom}[машинной арифметики]
    \[
        \fl(a\cdot b) = a\cdot b\cdot (1+\varepsilon), \quad |\varepsilon|\leqslant\eta\text{~--- <<машинный нуль>>}.
    \]
\end{axiom}

Если данная аксиома выполнена, можно рассмотреть теорему:

\begin{theorem}
    Пусть $\widetilde{L},\, \widetilde{U}$~--- машинные матрицы. Тогда \[\left|A-\widetilde{L}
        \cdot\widetilde{U}\right|\leqslant cn\eta\left(\left|A\right|+\left|\widetilde{L}\right|\cdot\left|\widetilde{U}\right|\right)+O(\eta^2),\]
    где $c$~--- некоторая константа.
\end{theorem}

В теореме видно, что большой вклад в погрешность вносят как раз матрицы $\widetilde{L}\text{ и }\widetilde{U}$. Как нужно изменить метод Гаусса, чтобы
ограничить рост элементов этих матриц?

Будем просто на место ведущего элемента выбирать наибольший в столбце, тогда в матрице $\widetilde{L}$ будет верно следующее неравенство:
$\left|\widetilde{L}_{ij}\right|\leqslant 1$. С матрицей $\widetilde{U}$ дела обстоят сложнее. Тем не менее, можно доказать следующее утверждение:
\begin{claim}
    \[
        \max_{i,\,j} \widetilde{U}_{ij}\leqslant 2^{n-1}\cdot \left(\max_{i,\,j} A_{ij}\right).
    \]
\end{claim}

\subsection{Матрицы вращения.}

Как ни удивительно, есть способы вообще избежать роста коэффициентов.
Рассмотрим матрицу:
\[
    Q = \left(
    \begin{array}{cc}
            \cos\varphi & -\sin\varphi \\
            \sin\varphi & \cos\varphi
        \end{array}
    \right), \quad Q^T = \left(
    \begin{array}{cc}
            \cos\varphi  & \sin\varphi \\
            -\sin\varphi & \cos\varphi
        \end{array}
    \right) = Q^{-1}.
\]

$Q$ называется \mdef{матрицей вращения}.

\begin{definition}
    Матрица $A$ называется \mdef{ортогональной}, если $A^TA=I$.
\end{definition}

Понятно, что матрица вращения является ортогональной. Оказывается, что с помощью матрицы вращения
тоже можно исключать значения, к примеру подберем матрицу вращения так, чтобы было выполнено:

\[
    \left(
    \begin{array}{cc}
            \cos\varphi & -\sin\varphi \\
            \sin\varphi & \cos\varphi
        \end{array}
    \right)\cdot
    \left(
    \begin{array}{c}
            a \\
            b
        \end{array}
    \right)=
    \left(
    \begin{array}{c}
            c \\
            0
        \end{array}
    \right).
\]
То есть $a\sin\varphi+b\cos\varphi=0$, понятно, что это всегда можно сделать:

\[
    \sin\varphi=-\dfrac{b}{\sqrt{a^2+b^2}},\quad \cos\varphi=\dfrac{a}{\sqrt{a^2+b^2}}.
\]

Научимся приводить матрицу к диагональному виду, используя этот прием. Но сначала важное понятие:

\begin{definition}
    Матрица $G_{kl}$ называется \mdef{обобщенной матрицей вращения} или
    \mdef{матрицей Гивенса}, если она отличается от единичной матрицей лишь подматрицей $Q$,
    расположенной на строках и столбцах с номерами $k$ и $l$.

    \[
        G_{kl}=
        \left[\begin{array}{ccccccc}
                1      & \cdots & 0         & \cdots & 0          & \cdots & 0      \\
                \vdots & \ddots & \vdots    &        & \vdots     &        & \vdots \\
                0      & \cdots & \cos \phi & \cdots & -\sin \phi & \cdots & 0      \\
                \vdots &        & \vdots    & \ddots & \vdots     &        & \vdots \\
                0      & \cdots & \sin \phi & \cdots & \cos \phi  & \cdots & 0      \\
                \vdots &        & \vdots    &        & \vdots     & \ddots & \vdots \\
                0      & \cdots & 0         & \cdots & 0          & \cdots & 1
            \end{array}\right]
    \]

    Примеры для лучшего понимания:
    \[
        G_{12}=\left(
        \begin{array}{ccccc}
                \cos & -\sin & 0 & \ldots & 0 \\
                \sin & \cos  & 0 & \ldots & 0 \\
                0    & 0     & 1 & \ldots & 0 \\
                \ldots                        \\
                0    & 0     & 0 & \ldots & 1
            \end{array}
        \right),\,
        G_{23}=\left(
        \begin{array}{ccccc}
                1 & 0    & 0     & \ldots & 0 \\
                0 & \cos & -\sin & \ldots & 0 \\
                0 & \sin & \cos  & \ldots & 0 \\
                \ldots                        \\
                0 & 0    & 0     & \ldots & 1
            \end{array}
        \right),\,\ldots
    \]
\end{definition}

Тогда умножив на некоторое число таких матриц (примерно $n^2$~--- столько же, сколько нужно сделать нулей)
получим треугольную матрицу: $Q_s\cdot \ldots \cdot Q_1\cdot A = U$, причем $Q_i=G_{k_i l_{i}}$~--- 
ортогональная матрица для всех $i$, поэтому
\[
    A = Q_{1}^{-1}\cdot\ldots Q_{s}^{-1}\cdot U = Q_{1}^{T}\cdot\ldots Q_{s}^{T}\cdot U\Rightarrow A = QU.
\]

\begin{claim}
    Произведение ортогональных матриц и обратная к ортогональной матрице являются ортогональными матрицами.

    \begin{proof}
        Пусть $A,\, B$~--- ортогональные, тогда
        \begin{enumerate}
            \item $(A^{-1})^TA^{-1}=(A^T)^{-1}A^{-1}=(AA^T)^{-1}=I$;
            \item $(AB)^T(AB) = B^TA^TAB=B^TIB=I$.
        \end{enumerate}
    \end{proof}
\end{claim}

\begin{definition}
    Построенное разложение матрицы называется \mdef{QR-разложением}. То есть матрица $A$
    имеет QR-разложение, если $A=QR$, где $Q$~--- ортогональная матрица, $R$~--- верхняя треугольная матрица.
\end{definition}

\begin{theorem}
    Для любой квадратной вещественной матрицы существует QR"=разложение.
\end{theorem}

Пусть $Q$~--- ортогональная матрица порядка $n$, значит по определению $Q^TQ=I$. Заметим, что 
$(Q^TQ)_{ij}=q^T_{i}q_j=(q_j,\, q_i)$~--- скалярное произведение. Более того
столбцы (и, конечно, строки) матрицы образуют ортонормированную систему, то есть 
\[
    (q_j,\, q_i)=\delta_{ij}=\begin{cases}
        1,\ i=j,\\
        0,\ i\neq j.
    \end{cases}\text{~--- символ Кронекера.}
\]

\begin{claim}
    Пусть есть линейно независимые столбцы: $\vect{a_1},\,\ldots,\,\vect{a_n}\in\R^n$. Утверждается, что 
    от них можно перейти к неким ортонормированным столбцам: $\vect{q_1},\,\ldots,\,\vect{q_n}$ с дополнительным свойством
    $L(\vect{q_1},\,\ldots,\,\vect{q_k})=L(\vect{a_1},\,\ldots,\,\vect{a_k})\ \forall k: 1\leqslant k\leqslant n$, где $L$~--- линейная
    оболочка векторов.

    \begin{proof}
        Доказательство использует важное понятие как процесс ортогонализации Грама-Шмидта: 
        \begin{align*}
            \vect{q_1}&=\dfrac{\vect{a_1}}{\|\vect{a_1}\|}\\
            \vect{p_2}&=\vect{a_2}-r_{12}\vect{q_1},\quad r_{12}=(\vect{a_2},\,\vect{q_1}),\quad 
            \vect{q_2}=\dfrac{\vect{p_2}}{\|\vect{p_2}\|}\\
            \ldots
        \end{align*}

    \end{proof}
\end{claim}

\begin{remark}
    Соответственно для получения QR-разложения матрицы $A$ используем процесс ортогонализации Грама-Шмидта: 
    новые столбцы составят матрицу $Q$, а коэффициенты $r_{ij}$ составят матрицу $R$.
\end{remark}

\begin{claim}
    Пусть $Q$~--- ортогональная матрицы. Тогда $\forall \vect{x}\in\R^n$ выполнено $\|Q\vect{x}\|=\|\vect{x}\|$.
    То есть при умножении вектора на ортогональную матрицу его длина не меняется.

    \begin{proof}
        \[\|Q\vect{x}\|=\sqrt{(Q\vect{x})^T(Q\vect{x})}=\sqrt{\vect{x}^TQ^TQx}=\|\vect{x}\|.\]

    \end{proof}
\end{claim}

\begin{next0}
    При умножении матрицы $A$ слева и справа на ортогональные матрицы сумма квадратов всех элементов 
    сохраняется.
\end{next0}

\begin{exercise}
    Пусть $A$~--- невырожденная нижняя треугольная матрица. Постройте алгоритм вычисления обратной матрицы $A^{-1}$
    с числом параллельных шагов $O(\log_2^2n)$.

    \textbf{Hint:} \mdef{Схема сдваивания.} Пусть требуется сложить $n$ чисел: 
    \[
        S = \underbrace{a_1+a_2}+\underbrace{a_3+a_4}+\underbrace{a_5+a_6}+\underbrace{\ldots+a_n}.   
    \]
    Если их разбить на пары и в каждой паре найти результат независимо, а потом применить такое же рассуждение 
    для результатов, то всего будет порядка $\log_2 n$ шагов.

    \begin{remark}
        Открытой проблемой является вопрос о существовании алгоритма с меньшей параллельной сложностью.
    \end{remark}
\end{exercise}

\begin{remark}
    Более того, известно, что произвольную невырожденную матрицу можно обратить, затратив $O(\log_2^2 n)$ 
    параллельных шагов.        
\end{remark}

