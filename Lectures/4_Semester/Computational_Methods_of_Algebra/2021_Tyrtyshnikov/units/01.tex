\newpage
\lecture{1}{Введение. Системы линейных уравнений.}

\subsection{Классы задач вычислительной алгебры.}

\begin{enumerate}[label=\protect\circled{\arabic*}]
	\item Решение системы линейных уравнений:
	      \[
		      Ax = b.
	      \]
	\item Задача наименьших квадратов:
	      \[
		      \|Ax-b\|\rightarrow \min.
	      \]
	\item Спектральные задачи~--- поиск собственных значений (векторов) матрицы:
	      \[
		      Ax=\lambda x.
	      \]
\end{enumerate}

Начнем с первого класса задач, но сначала краткая историческая справка, чтобы показать
полезность изучаемого предмета.

\begin{exercise}
	В 1991 году западная компания \textit{RSA Laboratories} запустила так называемый
	\textit{RSA Factoring Challenge} для поощрения исследований в области
	вычислительной теории чисел и практической сложности факторизации больших целых чисел.
	\textit{RSA Laboratories} опубликовала 54 полупростых\footnote[1]{Число $n$ называется полупростым, если $n = pq$, где
		$p,\, q$~--- простые числа.}
	числа длиной от 100 до 617 десятичных знаков.
	За факторизацию некоторых из них были предложены денежные призы. Наименьшее RSA-число было разложено за несколько дней.
	Большинство чисел до сих пор не разложены и предполагается, что многие из них останутся неразложенными
	ещё довольно долгое время.

	Данная задача тесно связана с проблемой изучения стойкости систем шифрования или криптосистем.
	К примеру рассматривается функция шифрования $f:\ \Z_n\rightarrow\Z_n$ такая, что $f(x)=x^e\ (\text{mod } n)$,
	где $e$ взаимно просто с $(p-1)(q-1)=\varphi(n)$. Для зашифровки сообщения нужно знать лишь $e$ и $n$,
	но для расшифровки нужно дополнительно знать и $p,\, q$, то есть факторизацию $n$.
\end{exercise}

Пример казалось бы никак не связан с системой линейных уравнений, но методы, применяемые для
решения данной задачи, активно используют методы алгебры. Сам алгоритм решения состоит из нескольких шагов:
\begin{enumerate}
	\item Построение системы линейных уравнений над полем $\F_2$.
	\item Поиск решения данной системы.
\end{enumerate}

\subsection{Факторизация матрицы.}
Рассмотрим систему $Ax=b$ и для определенности будем считать, что переменных столько же сколько и уравнений,
то есть $A$~--- квадратная, для простоты будем считать, что все числа вещественные.
Систему уравнений можно записать в виде:
\[\begin{cases}
		a_{11}x_1+a_{12}x_2+\ldots+a_{1n}x_n=b_1, \\
		a_{21}x_1+a_{22}x_2+\ldots+a_{2n}x_n=b_2, \\
		\ldots                                    \\
		a_{n1}x_1+a_{n2}x_2+\ldots+a_{nn}x_n=b_n.
	\end{cases}\]

Данная задача тесно связана с задачей факторизации матрицы, но для начала нужно ввести пару понятий:
\begin{definition}
	Если все элементы матрицы $A$ ниже (выше) главной диагонали равны нулю,
	то $A$ называется \mdef{нижней треугольной} (\mdef{верхней треугольной}).

	Если же вдобавок на главной диагонали стоят единицы, то тогда матрица называется $\mdef{нижней унитреугольной}$
	(\mdef{верхней унитреугольной}).
\end{definition}
\begin{definition}
	\mdef{LU-разложение}~--- представление матрицы $A$ в виде произведения двух матриц,
	$A=LU$, где $L$~--- нижняя треугольная матрица, а $U$~--- верхняя треугольная матрица.

	Будем без ограничения общности считать, что $L$~--- нижняя \textbf{унитреугольная},
	а матрица $U$~--- невырожденная.

	Соответственно говорят, что матрица имеет LU-разложение, если найдутся такие $L$ и $U$.
\end{definition}

\begin{remark}
	Не каждая матрица имеет LU-разложения. В самом деле, $L$ и $U$~--- невырожденные матрицы, а следовательно и их
	произведение является невырожденной матрицей. Можно усилить вопрос: любая ли невырожденная матрица имеет LU-разложение?
	Оказывается даже этого условия недостаточно.
\end{remark}

\begin{exercise}
	Более того, не любая невырожденная матрица имеет LU-разложение. Рассмотрим левые верхние блоки размером $k$ матриц $A,\, L$ и
	$U$:

	\[
		\left(
		\begin{array}{c|c}
				A_{k}  & \ldots \\
				\hline
				\ldots & \ldots
			\end{array}
		\right) =
		\left(
		\begin{array}{c|c}
				L_{k}  & 0      \\
				\hline
				\ldots & \ldots
			\end{array}
		\right)\cdot
		\left(
		\begin{array}{c|c}
				U_{k} & \ldots \\
				\hline
				0     & \ldots
			\end{array}
		\right),
	\]
	где $L_k,\, U_k$~--- нижне и верхне треугольные матрицы соответственно.

	Из блочного правила умножения матриц понятно, что $A_k=L_kU_k$, а значит по аналогичному рассуждению в замечании заключаем,
	что $A_k$~--- невырожденная для любого $k$.
\end{exercise}

Оказывается, что условие невырожденности каждой левой верхней подматрицы является не только необходимым, но и
достаточным. Введем еще одно понятие и зафиксируем это утверждение теоремой.

\begin{definition}
	Матрица $A$ называется \mdef{строго регулярной}, если все ведущие\footnote{матрица в левом верхнем углу}
	подматрицы $A_k$ матрицы $A$ невырождены.
\end{definition}

\begin{theorem}
	Для матрицы $A$ существует LU-разложение, тогда и только тогда, когда $A$ является строго регулярной матрицей.

	\begin{proof}
		\circled{$\Rightarrow$} Доказано выше в замечании к определению.

		\circled{$\Leftarrow$} В силу строго регулярности $a_{11}\neq 0$, используем это чтобы обнулить все в первом
		столбце (кроме первого элемента):
		\[
			\left(
			\begin{array}{cccc}
					1           & 0 & \ldots  & 0 \\
					\gamma_{21} &                 \\
					\ldots      &   & I_{n-1}     \\
					\gamma_{n1} &
				\end{array}
			\right)\cdot
			\left(
			\begin{array}{cccc}
					a_{11} & a_{12} & \ldots & a_{1n} \\
					a_{21} &                          \\
					\ldots &        & A_{22}          \\
					a_{n1}
				\end{array}
			\right) =
			\left(
			\begin{array}{cccc}
					a_{11} & a_{12} & \ldots & a_{1n} \\
					0      &                          \\
					\ldots &        & H               \\
					0
				\end{array}
			\right),
			\quad \gamma_{i1}=-\dfrac{a_{i1}}{a_{11}}.
		\]
		Дальше заметим, что $H$~--- тоже строго регулярная, и доказательство завершается по индукции.

	\end{proof}
\end{theorem}

\begin{exercise}
	Строгая регулярность \textbf{не} сохраняется при перестановке строк матрицы:
	\[
		\left(
		\begin{array}{cc}
				0 & 1 \\
				1 & 0
			\end{array}
		\right)\rightarrow
		\left(
		\begin{array}{cc}
				1 & 0 \\
				0 & 1
			\end{array}
		\right)
	\]
\end{exercise}

\begin{claim}
	Для любой невырожденной матрицы существует перестановка строк, которая делает ее строго регулярной.
\end{claim}

\begin{next0}
	Для любой невырожденной матрицы $A$ существует разложение
	\[
		A = PLU,
	\]
	где $L,\, U$~--- уже знакомые нам матрицы, а $P$~--- матрица перестановки (которая, очевидно,
	получается путем перестановки строк в единичной матрице).
\end{next0}

\subsection{Применение к системе линейных уравнений.}

Будем умножать уравнение $Ax=b$ слева матрицами $L_i$ специального вида:
\[
	L_1 = \left(
	\begin{array}{ccccc}
			1      & 0 & 0 & \ldots & 0 \\
			\times & 1 & 0 & \ldots & 0 \\
			\times & 0 & 1 & \ldots & 0 \\
			\ldots &                    \\
			\times & 0 & 0 & \ldots & 1
		\end{array}
	\right),\,
	L_2 = \left(
	\begin{array}{ccccc}
			1      & 0      & 0 & \ldots & 0 \\
			0      & 1      & 0 & \ldots & 0 \\
			0      & \times & 1 & \ldots & 0 \\
			\ldots &                         \\
			0      & \times & 0 & \ldots & 1
		\end{array}
	\right),\,
	L_3 = \ldots,
\]
то есть в матрице $L_i$ под единичками не нули только в $i$"=ом столбце (значения соответствуют
значениям $\gamma$, введенным выше). Итак,
уравнение $Ax=b$ преобразовали в уравнение
\[L_{n-1}\cdot\ldots\cdot L_1\cdot A\cdot x = L_{n-1}\cdot\ldots\cdot L_1\cdot b.\]
Тогда $\hat{L}A=U$ или, умножив в нужном порядке
на обратные: $A = L_{1}^{-1}\cdot\ldots\cdot L^{-1}_{n-1}\cdot U=LU$.
\begin{remark}
	Можно заметить, что произведение $L_{1}\cdot\ldots\cdot L_{n-1}$ (и, конечно, обратных к этим матриц)
	имеем вид
	нижней унитреугольной матрицы, причем все столбцы как-будто переехали из соответствующих матриц,
	частный пример для понимания:
	\[
		\left(
		\begin{array}{ccc}
				1 & 0 & 0 \\
				a & 1 & 0 \\
				b & 0 & 1
			\end{array}
		\right)\cdot
		\left(
		\begin{array}{ccc}
				1 & 0 & 0 \\
				0 & 1 & 0 \\
				0 & c & 1
			\end{array}
		\right)=
		\left(
		\begin{array}{ccc}
				1 & 0 & 0 \\
				a & 1 & 0 \\
				b & c & 1
			\end{array}
		\right).
	\]
\end{remark}

\begin{remark}
	Заметим, что и $L_{i}^{-1}$ очень хорошо связано с $L_{i}$, к примеру для $L_1$:
	\[
		L_1 = \left(
		\begin{array}{ccccc}
				1      & 0 & 0 & \ldots & 0 \\
				\times & 1 & 0 & \ldots & 0 \\
				\times & 0 & 1 & \ldots & 0 \\
				\ldots &                    \\
				\times & 0 & 0 & \ldots & 1
			\end{array}
		\right),\,
		L_1^{-1} = \left(
		\begin{array}{ccccc}
				1       & 0 & 0 & \ldots & 0 \\
				-\times & 1 & 0 & \ldots & 0 \\
				-\times & 0 & 1 & \ldots & 0 \\
				\ldots  &                    \\
				-\times & 0 & 0 & \ldots & 1
			\end{array}
		\right).
	\]
\end{remark}

\subsection{Алгоритм решения.}

Итак, мы уже готовы составить план алгоритма для решения системы линейных уравнений.

\begin{enumerate}[label=\protect\circled{\arabic*}]
	\item Вычисление LU-разложения: $A=LU$;
	\item решение системы $Ly=b$;
	\item решение системы $Ux=y$.
\end{enumerate}

\begin{definition}
	\mdef{Алгоритм}~--- последовательность операций, берущихся из фиксированного набора основных базовых
	операций. Можно договориться, что основным набором у нас будут арифметические операции.
\end{definition}

\begin{definition}
	\mdef{Арифметическая сложность алгоритма} не что иное, как количество операций в нём.
\end{definition}

Найдем сложность построенного алгоритма в зависимости от $n$~--- порядок матрицы $A$.
Для каждого этапа найдем число операций:
\begin{enumerate}[label=\protect\circled{\arabic*}]
	\item Для обнуления $i$"=го столбца нужно $(n-i)^2$ операций сложения и умножения. Тогда всего будет
	      $\sum\limits_{i=1}^{n-1} (n-i)^2=\dfrac{n^3}{3}+O(n^2)$ операций сложения и умножения.
	      Всего операций получаем $\dfrac{2}{3}n^3+O(n^2)$.
	\item Матрица имеет треугольный вид, а значит решения найти можно легко:
	      \begin{align*}
		      y_1 & =b_1                       \\
		      y_2 & =b_2-x\cdot y_1            \\
		      y_3 & =b_3-x\cdot y_1-x\cdot y_2 \\
		          & \ldots
	      \end{align*}

	      Всего получится $\dfrac{n^2}{2}+O(n)$ действий сложения и умножения, то есть итого $n^2+O(n)$.
	\item Аналогично предыдущему.
\end{enumerate}

Итак, арифметическая сложность алгоритма: $\dfrac{2}{3}n^3+O(n^2)$.

\begin{remark}
	Полезное наблюдение: второй и третий этапы на порядок быстрее первого. А значит если стоит задача
	о нахождении решения разных систем уравнений с постоянными коэффициентами ($A=\text{const}$,
	а $b$ меняется), то $m$ систем можно будет решить за $mn^2+O(mn)$
	операций с начальными расчетами за $\dfrac{2}{3}n^3+O(n^2)$.
\end{remark}

\begin{remark}
	Это \textbf{не} самый быстрый алгоритм. Существуют алгоритмы с $O(n^{\alpha})$ операциями, где
	$\alpha\in (2,\, 3)$. К примеру алгоритм, использующий алгоритм Штрассена для умножения
	матриц (1969 год) ($\alpha=\log_{2}7\approx 2.81$).
\end{remark}

\subsection{Алгоритм Штрассена.}
Допустим мы умеем умножать блочные матрицы $2\times 2$ за 7 умножений матриц (вместо 8 в тривиальном алгоритме).
Тогда можно записать рекуррентное соотношение
\[
	T(n) = 7\cdot T\left(\frac{n}{2}\right)+\Theta(n^2),
\]
откуда итоговое число операций $\Theta(n^{\log_2 7})$.

Как теперь используя данный алгоритм найти решения системы линейных уравнений? Будем искать обратную матрицу.

\[
	A =
	\left(
	\begin{array}{cc}
			A_{11} & A_{12} \\
			A_{21} & A_{22}
		\end{array}
	\right)=
	\left(
	\begin{array}{cc}
			I                  & 0 \\
			-A_{21}A_{11}^{-1} & I
		\end{array}
	\right)\cdot
	\left(
	\begin{array}{cc}
			A_{11} & 0 \\
			0      & H
		\end{array}
	\right)\cdot
	\left(
	\begin{array}{cc}
			I & A_{11}^{-1}A_{12} \\
			0 & I
		\end{array}
	\right),
\]
где $H = A_{22}-A_{21}A_{11}^{-1}A_{12}$.

Откуда легко видеть, что
\[
	A^{-1} =
	\left(
	\begin{array}{cc}
			I & -A_{11}^{-1}A_{12} \\
			0 & I
		\end{array}
	\right)\cdot
	\left(
	\begin{array}{cc}
			A_{11}^{-1} & 0      \\
			0           & H^{-1}
		\end{array}
	\right)\cdot
	\left(
	\begin{array}{cc}
			I                  & 0 \\
			-A_{21}A_{11}^{-1} & I
		\end{array}
	\right).
\]

То есть задача об обратимости матрицы $n\times n$ свелась к двум задачам обратимости матриц размером
$\frac{n}{2}\times \frac{n}{2}$ и некоторому числу умножений. То есть рекуррента принимает вид
\[
	T(n)=2T\left(\dfrac{n}{2}\right)+\Theta(n^{\alpha}),\quad \alpha=\log_{2}7.
\]
Из мастер теоремы видно, что если $\alpha>1$, то итого будет $\Theta(n^{\alpha})$ операций.

\begin{claim}
	Если существует алгоритм, умножающий две матрицы за $O(n^{\alpha})$ операций, то
	и существует алгоритм, находящий обратную матрицу за $O(n^{\alpha})$ операций.

	Доказательство по существу уже написано выше.
\end{claim}